{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPKo7qbOSyEgjMqEJFJrXRA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\", force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfsPWPb0atqC","executionInfo":{"status":"ok","timestamp":1733936669836,"user_tz":-420,"elapsed":7715,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}},"outputId":"3d741bd8-8543-4bc5-8561-cf82aa8e72a8"},"execution_count":142,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["%cd '/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPbC9j8KatSb","outputId":"2d6067fb-f32a-41c8-b5df-67975caa3e26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-143-fc6f2c8d5253>\", line 1, in <cell line: 1>\n","    get_ipython().run_line_magic('cd', \"'/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy'\")\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2418, in run_line_magic\n","    result = fn(*args, **kwargs)\n","  File \"<decorator-gen-85>\", line 2, in cd\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\", line 187, in <lambda>\n","    call = lambda f, *a, **k: f(*a, **k)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\", line 342, in cd\n","    oldcwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-143-fc6f2c8d5253>\", line 1, in <cell line: 1>\n","    get_ipython().run_line_magic('cd', \"'/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy'\")\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2418, in run_line_magic\n","    result = fn(*args, **kwargs)\n","  File \"<decorator-gen-85>\", line 2, in cd\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\", line 187, in <lambda>\n","    call = lambda f, *a, **k: f(*a, **k)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\", line 342, in cd\n","    oldcwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-143-fc6f2c8d5253>\", line 1, in <cell line: 1>\n","    get_ipython().run_line_magic('cd', \"'/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy'\")\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2418, in run_line_magic\n","    result = fn(*args, **kwargs)\n","  File \"<decorator-gen-85>\", line 2, in cd\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\", line 187, in <lambda>\n","    call = lambda f, *a, **k: f(*a, **k)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\", line 342, in cd\n","    oldcwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n","    self.showtraceback()\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n","    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]}]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"DOt1HfaufZgX","executionInfo":{"status":"ok","timestamp":1733936669836,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":143,"outputs":[]},{"cell_type":"code","source":["# # Load the CSV file into a DataFrame\n","# file_path = '/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy/Danh_gia.csv'  # Make sure to provide the correct file path\n","# df = pd.read_csv(file_path)"],"metadata":{"id":"ppGp507fbzhp","executionInfo":{"status":"ok","timestamp":1733936669836,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":144,"outputs":[]},{"cell_type":"code","source":["!pip install polars"],"metadata":{"id":"oSuXPjfDhV6o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733936671122,"user_tz":-420,"elapsed":1288,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}},"outputId":"30212887-9730-498f-f4fb-91c5cfc3fcb9"},"execution_count":145,"outputs":[{"output_type":"stream","name":"stdout","text":["shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n","shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 5, in <module>\n","    from pip._internal.cli.main import main\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 11, in <module>\n","    from pip._internal.cli.autocompletion import autocomplete\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n","    from pip._internal.cli.main_parser import create_main_parser\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n","    from pip._internal.build_env import get_runnable_pip\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n","    from pip._internal.cli.spinners import open_spinner\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n","    from pip._internal.utils.logging import get_indentation\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n","    from pip._vendor.rich.console import (\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/__init__.py\", line 17, in <module>\n","    _IMPORT_CWD = os.path.abspath(os.getcwd())\n","OSError: [Errno 107] Transport endpoint is not connected\n"]}]},{"cell_type":"code","source":["import polars as pl\n","from functools import lru_cache"],"metadata":{"id":"RmBDZw5RhV4P","executionInfo":{"status":"ok","timestamp":1733936671122,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":146,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"S7zkLKbvDwD8","executionInfo":{"status":"ok","timestamp":1733936671123,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":146,"outputs":[]},{"cell_type":"code","source":["# def load_keywords(filename):\n","#     \"\"\"\n","#     Đọc keywords từ file txt\n","#     Format file txt:\n","#     key_phrases: từ1, từ2, từ3\n","#     positive_words: từ1, từ2, từ3\n","#     negative_words: từ1, từ2, từ3\n","#     \"\"\"\n","#     keywords = {}\n","#     with open(filename, 'r', encoding='utf-8') as f:\n","#         for line in f:\n","#             if ':' in line:\n","#                 key, values = line.strip().split(':')\n","#                 keywords[key.strip()] = [v.strip() for v in values.split(',')]\n","#     return keywords"],"metadata":{"id":"yPxUVNhshVxR","executionInfo":{"status":"ok","timestamp":1733936671123,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":147,"outputs":[]},{"cell_type":"code","source":["@lru_cache(maxsize=None)\n","def load_keywords(filename):\n","    keywords = {}\n","    with open(filename, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            if ':' in line:\n","                key, values = line.strip().split(':')\n","                keywords[key.strip()] = set(v.strip() for v in values.split(','))\n","    return keywords\n"],"metadata":{"id":"i4BZ_B_QDVO9","executionInfo":{"status":"ok","timestamp":1733936671123,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":148,"outputs":[]},{"cell_type":"code","source":["# First read the stopwords from file\n","with open('/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy/vietnamese-stopwords.txt', 'r', encoding='utf-8') as file:\n","    stop_words = set(file.read().splitlines())  # Creates a set of stopwords"],"metadata":{"id":"LXNOoy_D_wf4","executionInfo":{"status":"ok","timestamp":1733936671123,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":149,"outputs":[]},{"cell_type":"code","source":["# def check_content(row, category, keywords):\n","#     \"\"\"\n","#     Hàm chung để check nội dung theo category (san_pham/dich_vu/giao_hang)\n","#     Ưu tiên check negative words trước, sau đó xóa negative words khỏi content\n","#     trước khi check positive words\n","#     \"\"\"\n","#     content = str(row['noi_dung_binh_luan']).lower()\n","\n","#     # Remove stopwords\n","#     words = content.split()  # Split into words\n","#     filtered_words = [word for word in words if word not in stop_words]\n","\n","#     # Join the words back together\n","#     content = ' '.join(filtered_words)\n","\n","#     key_phrases = keywords['key_phrases']\n","#     positive_words = keywords['positive_words']\n","#     negative_words = keywords['negative_words']\n","\n","#     # Check key phrases first\n","#     for phrase in key_phrases:\n","#         if phrase in content:\n","#             phrase_index = content.index(phrase)\n","#             trimmed_content = content[phrase_index:]\n","\n","#             # Check negative words first\n","#             for word in negative_words:\n","#                 if word in trimmed_content:\n","#                     return pd.Series(['negative', f'{phrase} {word}'])\n","\n","#             # Remove all negative words from content before checking positive\n","#             cleaned_content = trimmed_content\n","#             for neg_word in negative_words:\n","#                 cleaned_content = cleaned_content.replace(neg_word, '')\n","\n","#             # Check positive words in cleaned content\n","#             for word in positive_words:\n","#                 if word in cleaned_content:\n","#                     return pd.Series(['positive', f'{phrase} {word}'])\n","\n","#     # Nếu không tìm thấy key phrases và là category san_pham\n","#     if category == 'san_pham':\n","#         # Check negative words first\n","#         for word in negative_words:\n","#             if word in content:\n","#                 return pd.Series(['negative', f'sản phẩm {word}'])\n","\n","#         # Remove negative words before checking positive\n","#         cleaned_content = content\n","#         for neg_word in negative_words:\n","#             cleaned_content = cleaned_content.replace(neg_word, '')\n","\n","#         # Check positive words\n","#         for word in positive_words:\n","#             if word in cleaned_content:\n","#                 return pd.Series(['positive', f'sản phẩm {word}'])\n","\n","#     return pd.Series(['neutral', ''])"],"metadata":{"id":"6oj4MB79juME","executionInfo":{"status":"ok","timestamp":1733936671123,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":150,"outputs":[]},{"cell_type":"code","source":["# def check_content_polars(df: pl.DataFrame, category: str, keywords: dict) -> pl.DataFrame:\n","#     key_phrases = list(keywords['key_phrases'])\n","#     positive_words = list(keywords['positive_words'])\n","#     negative_words = list(keywords['negative_words'])\n","\n","#     # Convert content to lowercase and remove stopwords\n","#     df = df.with_columns([\n","#         pl.col('noi_dung_binh_luan').str.to_lowercase().alias('content_lower')\n","#     ])\n","\n","#     # Remove stopwords\n","#     df = df.with_columns([\n","#         pl.col('content_lower').str.split(' ').map(\n","#             lambda x: ' '.join([w for w in x if w not in stop_words])\n","#         ).alias('cleaned_content')\n","#     ])\n","\n","#     # Create expressions for matching\n","#     def create_matches(content, phrases):\n","#         return pl.any([pl.col(content).str.contains(phrase) for phrase in phrases])\n","\n","#     # Process sentiments\n","#     df = df.with_columns([\n","#         pl.when(create_matches('cleaned_content', key_phrases))\n","#         .then(\n","#             pl.when(create_matches('cleaned_content', negative_words))\n","#             .then(pl.lit('negative'))\n","#             .otherwise(\n","#                 pl.when(create_matches('cleaned_content', positive_words))\n","#                 .then(pl.lit('positive'))\n","#                 .otherwise(pl.lit('neutral'))\n","#             )\n","#         )\n","#         .otherwise(\n","#             pl.when(category == 'san_pham')\n","#             .then(\n","#                 pl.when(create_matches('cleaned_content', negative_words))\n","#                 .then(pl.lit('negative'))\n","#                 .otherwise(\n","#                     pl.when(create_matches('cleaned_content', positive_words))\n","#                     .then(pl.lit('positive'))\n","#                     .otherwise(pl.lit('neutral'))\n","#                 )\n","#             )\n","#             .otherwise(pl.lit('neutral'))\n","#         )\n","#         .alias(category)\n","#     ])\n","\n","#     # Find matching keywords\n","#     def find_keywords(row):\n","#         content = row['cleaned_content']\n","\n","#         for phrase in key_phrases:\n","#             if phrase in content:\n","#                 for neg in negative_words:\n","#                     if neg in content:\n","#                         return f'{phrase} {neg}'\n","#                 for pos in positive_words:\n","#                     if pos in content:\n","#                         return f'{phrase} {pos}'\n","\n","#         if category == 'san_pham':\n","#             for neg in negative_words:\n","#                 if neg in content:\n","#                     return f'sản phẩm {neg}'\n","#             for pos in positive_words:\n","#                 if pos in content:\n","#                     return f'sản phẩm {pos}'\n","\n","#         return ''\n","\n","#     df = df.with_columns([\n","#         pl.struct(['cleaned_content']).map_rows(find_keywords).alias(f'{category}_kw')\n","#     ])\n","\n","#     return df.select([category, f'{category}_kw'])"],"metadata":{"id":"VF1Yiec9DbAk","executionInfo":{"status":"ok","timestamp":1733936671123,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":151,"outputs":[]},{"cell_type":"code","source":["def check_content_polars(df: pl.DataFrame, category: str, keywords: dict, stop_words: set) -> pl.DataFrame:\n","    # Extract keywords from the keywords dictionary\n","    key_phrases = keywords['key_phrases']\n","    positive_words = set(keywords['positive_words'])  # Use set for faster lookup\n","    negative_words = set(keywords['negative_words'])\n","\n","    # Convert content to lowercase\n","    df = df.with_columns(\n","        pl.col('noi_dung_binh_luan').str.to_lowercase().alias('content_lower')\n","    )\n","\n","    # Remove stop words and create cleaned content\n","    df = df.with_columns([\n","        pl.col('content_lower').str.split(' ').map_elements(\n","            lambda x: ' '.join([word for word in x if word not in stop_words]),\n","            return_dtype=pl.Utf8\n","        ).alias('cleaned_content')\n","    ])\n","\n","    # Initialize lists for results\n","    sentiment_col = []\n","    keyword_col = []\n","\n","    # Iterate over each row in the DataFrame\n","    for row in df.iter_rows(named=True):\n","        found = False\n","\n","        # Check if cleaned_content is None or empty\n","        cleaned_content = row['cleaned_content']\n","        if cleaned_content is None or cleaned_content == '':\n","            cleaned_content = ''\n","\n","        for phrase in key_phrases:\n","            if phrase in cleaned_content:\n","                # Check negative words first\n","                for neg_word in negative_words:\n","                    if neg_word in cleaned_content:\n","                        sentiment_col.append('negative')\n","                        keyword_col.append(f'{phrase} {neg_word}')\n","                        found = True\n","                        break  # Break out of the negative check\n","                if found:  # If already found a negative word, no need to check further\n","                    break\n","\n","                # If no negatives, check for positives\n","                for pos_word in positive_words:\n","                    if pos_word in cleaned_content:\n","                        sentiment_col.append('positive')\n","                        keyword_col.append(f'{phrase} {pos_word}')\n","                        found = True\n","                        break\n","                if found:\n","                    break  # Break out if we've found a sentiment\n","\n","        if not found:\n","            # No phrases found or no sentiment detected; check based on the category\n","            if category == 'san_pham':\n","                # Check for any negative word in the entire cleaned content\n","                for neg_word in negative_words:\n","                    if neg_word in cleaned_content:\n","                        sentiment_col.append('negative')\n","                        keyword_col.append(f'sản phẩm {neg_word}')\n","                        found = True\n","                        break\n","\n","                if not found:\n","                    # Check for positive words\n","                    for pos_word in positive_words:\n","                        if pos_word in cleaned_content:\n","                            sentiment_col.append('positive')\n","                            keyword_col.append(f'sản phẩm {pos_word}')\n","                            found = True\n","                            break\n","\n","            if not found:  # If nothing matched, it's neutral\n","                sentiment_col.append('neutral')\n","                keyword_col.append('')\n","\n","    # Add the results to the DataFrame\n","    df = df.with_columns([\n","        pl.Series(name=f\"{category}\", values=sentiment_col),\n","        pl.Series(name=f\"{category}_kw\", values=keyword_col)\n","    ])\n","\n","    return df"],"metadata":{"id":"4qdmL08sEYwM","executionInfo":{"status":"ok","timestamp":1733936671123,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":152,"outputs":[]},{"cell_type":"code","source":["# # Sử dụng:\n","# def analyze_comments(df):\n","#     # Load keywords cho từng loại\n","#     san_pham_kw = load_keywords('/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy/san_pham_keywords.txt')\n","#     dich_vu_kw = load_keywords('/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy/dich_vu_keywords.txt')\n","#     giao_hang_kw = load_keywords('/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy/giao_hang_keywords.txt')\n","\n","#     # Check từng loại và tạo cột mới\n","#     df[['san_pham', 'san_pham_kw']] = df.apply(lambda x: check_content(x, 'san_pham', san_pham_kw), axis=1)\n","#     df[['dich_vu', 'dich_vu_kw']] = df.apply(lambda x: check_content(x, 'dich_vu', dich_vu_kw), axis=1)\n","#     df[['giao_hang', 'giao_hang_kw']] = df.apply(lambda x: check_content(x, 'giao_hang', giao_hang_kw), axis=1)\n","\n","#     return df"],"metadata":{"id":"F5kpjH07hVsN","executionInfo":{"status":"ok","timestamp":1733936671123,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":153,"outputs":[]},{"cell_type":"code","source":["# def analyze_comments(df: pl.DataFrame) -> pl.DataFrame:\n","#     # Load keywords\n","#     san_pham_kw = load_keywords('/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy/san_pham_keywords.txt')\n","#     dich_vu_kw = load_keywords('/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy/dich_vu_keywords.txt')\n","#     giao_hang_kw = load_keywords('/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy/giao_hang_keywords.txt')\n","\n","#     # Process each category\n","#     results_sp = check_content_polars(df, 'san_pham', san_pham_kw)\n","#     results_dv = check_content_polars(df, 'dich_vu', dich_vu_kw)\n","#     results_gh = check_content_polars(df, 'giao_hang', giao_hang_kw)\n","\n","#     # Combine results\n","#     return df.with_columns([\n","#         *results_sp.columns,\n","#         *results_dv.columns,\n","#         *results_gh.columns\n","#     ])"],"metadata":{"id":"zX7UAK5Z_lke","executionInfo":{"status":"ok","timestamp":1733936671123,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":154,"outputs":[]},{"cell_type":"code","source":["def analyze_comments(df: pl.DataFrame) -> pl.DataFrame:\n","    # Load keywords for each type\n","    san_pham_kw = load_keywords('/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy/san_pham_keywords.txt')\n","    dich_vu_kw = load_keywords('/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy/dich_vu_keywords.txt')\n","    giao_hang_kw = load_keywords('/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy/giao_hang_keywords.txt')\n","\n","    # Process each category and extend DataFrame accordingly\n","    df = check_content_polars(df, 'san_pham', san_pham_kw, stop_words)\n","    df = check_content_polars(df, 'dich_vu', dich_vu_kw, stop_words)\n","    df = check_content_polars(df, 'giao_hang', giao_hang_kw, stop_words)\n","\n","    return df"],"metadata":{"id":"ur_GsF06Ez1j","executionInfo":{"status":"ok","timestamp":1733936671123,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":155,"outputs":[]},{"cell_type":"code","source":["# # Phân tích comments\n","# df = analyze_comments(df)\n","\n","# # df.to_csv('df.csv', index=False)"],"metadata":{"id":"68cPPDnxkDGE","executionInfo":{"status":"ok","timestamp":1733936671123,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":156,"outputs":[]},{"cell_type":"code","source":["# Or read directly with polars\n","df_pl = pl.read_csv('/content/gdrive/MyDrive/Classroom/DL07_k299_T27 Data Science & Machine Learning/DL07_K299_NguyenChanNam/Seniment_Analysis/GUI_project1_Copy/GUI_project1_Copy/Danh_gia.csv')\n","\n","# Process\n","result_df = analyze_comments(df_pl)"],"metadata":{"id":"A6eUU9F-D9es","executionInfo":{"status":"ok","timestamp":1733936674373,"user_tz":-420,"elapsed":3254,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}}},"execution_count":157,"outputs":[]},{"cell_type":"code","source":["result_df.head(50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"fn7jiSKUnvFS","executionInfo":{"status":"ok","timestamp":1733936674373,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}},"outputId":"f3301eee-7485-46b9-8345-1d46ee39e904"},"execution_count":158,"outputs":[{"output_type":"execute_result","data":{"text/plain":["shape: (50, 15)\n","┌─────┬─────────────┬─────────────┬────────────┬───┬─────────┬────────────┬───────────┬────────────┐\n","│ id  ┆ ma_khach_ha ┆ noi_dung_bi ┆ ngay_binh_ ┆ … ┆ dich_vu ┆ dich_vu_kw ┆ giao_hang ┆ giao_hang_ │\n","│ --- ┆ ng          ┆ nh_luan     ┆ luan       ┆   ┆ ---     ┆ ---        ┆ ---       ┆ kw         │\n","│ i64 ┆ ---         ┆ ---         ┆ ---        ┆   ┆ str     ┆ str        ┆ str       ┆ ---        │\n","│     ┆ i64         ┆ str         ┆ str        ┆   ┆         ┆            ┆           ┆ str        │\n","╞═════╪═════════════╪═════════════╪════════════╪═══╪═════════╪════════════╪═══════════╪════════════╡\n","│ 1   ┆ 443         ┆ SỬ DỤNG DỄ  ┆ 29/04/2023 ┆ … ┆ neutral ┆            ┆ neutral   ┆            │\n","│     ┆             ┆ DÀNG, RẤT   ┆            ┆   ┆         ┆            ┆           ┆            │\n","│     ┆             ┆ THOẢI MÁI…  ┆            ┆   ┆         ┆            ┆           ┆            │\n","│ 2   ┆ 1030        ┆ Sử dụng dễ  ┆ 30/04/2023 ┆ … ┆ neutral ┆            ┆ neutral   ┆            │\n","│     ┆             ┆ dãng,rất    ┆            ┆   ┆         ┆            ┆           ┆            │\n","│     ┆             ┆ thoải mái,… ┆            ┆   ┆         ┆            ┆           ┆            │\n","│ 3   ┆ 689         ┆ Mình rất    ┆ 30/04/2023 ┆ … ┆ neutral ┆            ┆ neutral   ┆            │\n","│     ┆             ┆ thích       ┆            ┆   ┆         ┆            ┆           ┆            │\n","│     ┆             ┆ hasaki va   ┆            ┆   ┆         ┆            ┆           ┆            │\n","│     ┆             ┆ sp tẩ…      ┆            ┆   ┆         ┆            ┆           ┆            │\n","│ 4   ┆ 2519        ┆ Sản phẩm có ┆ 17/07/2022 ┆ … ┆ neutral ┆            ┆ neutral   ┆            │\n","│     ┆             ┆ khả năng    ┆            ┆   ┆         ┆            ┆           ┆            │\n","│     ┆             ┆ làm sạch …  ┆            ┆   ┆         ┆            ┆           ┆            │\n","│ 5   ┆ 402         ┆ Sữa rửa mặt ┆ 15/04/2023 ┆ … ┆ neutral ┆            ┆ neutral   ┆            │\n","│     ┆             ┆ tốt,sạch    ┆            ┆   ┆         ┆            ┆           ┆            │\n","│     ┆             ┆ mụn,mịn d…  ┆            ┆   ┆         ┆            ┆           ┆            │\n","│ …   ┆ …           ┆ …           ┆ …          ┆ … ┆ …       ┆ …          ┆ …         ┆ …          │\n","│ 46  ┆ 2344        ┆ SỬ DỤNG DỄ  ┆ 1/5/2023   ┆ … ┆ neutral ┆            ┆ neutral   ┆            │\n","│     ┆             ┆ DÀNG, RẤT   ┆            ┆   ┆         ┆            ┆           ┆            │\n","│     ┆             ┆ THOẢI MÁI…  ┆            ┆   ┆         ┆            ┆           ┆            │\n","│ 47  ┆ 2893        ┆ Sản phẩm    ┆ 1/2/2021   ┆ … ┆ neutral ┆            ┆ neutral   ┆            │\n","│     ┆             ┆ bao bì đẹp, ┆            ┆   ┆         ┆            ┆           ┆            │\n","│     ┆             ┆ thấm nhan…  ┆            ┆   ┆         ┆            ┆           ┆            │\n","│ 48  ┆ 182         ┆ tẩy trang   ┆ 28/05/2022 ┆ … ┆ neutral ┆            ┆ neutral   ┆            │\n","│     ┆             ┆ tốt, nhưng  ┆            ┆   ┆         ┆            ┆           ┆            │\n","│     ┆             ┆ quà tặng …  ┆            ┆   ┆         ┆            ┆           ┆            │\n","│ 49  ┆ 3810        ┆ đây là lọ   ┆ 14/05/2024 ┆ … ┆ neutral ┆            ┆ neutral   ┆            │\n","│     ┆             ┆ kem dưỡng   ┆            ┆   ┆         ┆            ┆           ┆            │\n","│     ┆             ┆ ẩm mà tui … ┆            ┆   ┆         ┆            ┆           ┆            │\n","│ 50  ┆ 1637        ┆ Mình da     ┆ 24/07/2024 ┆ … ┆ neutral ┆            ┆ neutral   ┆            │\n","│     ┆             ┆ khô, tuy    ┆            ┆   ┆         ┆            ┆           ┆            │\n","│     ┆             ┆ nhiên dùng  ┆            ┆   ┆         ┆            ┆           ┆            │\n","│     ┆             ┆ vi…         ┆            ┆   ┆         ┆            ┆           ┆            │\n","└─────┴─────────────┴─────────────┴────────────┴───┴─────────┴────────────┴───────────┴────────────┘"],"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (50, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>ma_khach_hang</th><th>noi_dung_binh_luan</th><th>ngay_binh_luan</th><th>gio_binh_luan</th><th>so_sao</th><th>ma_san_pham</th><th>content_lower</th><th>cleaned_content</th><th>san_pham</th><th>san_pham_kw</th><th>dich_vu</th><th>dich_vu_kw</th><th>giao_hang</th><th>giao_hang_kw</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>443</td><td>&quot;SỬ DỤNG DỄ DÀNG, RẤT THOẢI MÁI…</td><td>&quot;29/04/2023&quot;</td><td>&quot;17:06&quot;</td><td>5</td><td>308500015</td><td>&quot;sử dụng dễ dàng, rất thoải mái…</td><td>&quot;sử dụng dàng, thoải mái, thư g…</td><td>&quot;positive&quot;</td><td>&quot;sản phẩm thư giãn&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td></tr><tr><td>2</td><td>1030</td><td>&quot;Sử dụng dễ dãng,rất thoải mái,…</td><td>&quot;30/04/2023&quot;</td><td>&quot;15:04&quot;</td><td>5</td><td>308500015</td><td>&quot;sử dụng dễ dãng,rất thoải mái,…</td><td>&quot;sử dụng dãng,rất thoải mái,thư…</td><td>&quot;positive&quot;</td><td>&quot;sản phẩm thư giãn&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td></tr><tr><td>3</td><td>689</td><td>&quot;Mình rất thích hasaki va sp tẩ…</td><td>&quot;30/04/2023&quot;</td><td>&quot;18:34&quot;</td><td>5</td><td>422216594</td><td>&quot;mình rất thích hasaki va sp tẩ…</td><td>&quot;thích hasaki va sp tẩy trang&quot;</td><td>&quot;positive&quot;</td><td>&quot;sp thích&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td></tr><tr><td>4</td><td>2519</td><td>&quot;Sản phẩm có khả năng làm sạch …</td><td>&quot;17/07/2022&quot;</td><td>&quot;13:48&quot;</td><td>5</td><td>204100075</td><td>&quot;sản phẩm có khả năng làm sạch …</td><td>&quot;sản phẩm khả năng sạch tốt. lớ…</td><td>&quot;negative&quot;</td><td>&quot;sản phẩm không sạch&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td></tr><tr><td>5</td><td>402</td><td>&quot;Sữa rửa mặt tốt,sạch mụn,mịn d…</td><td>&quot;15/04/2023&quot;</td><td>&quot;23:04&quot;</td><td>5</td><td>422208977</td><td>&quot;sữa rửa mặt tốt,sạch mụn,mịn d…</td><td>&quot;sữa rửa mặt tốt,sạch mụn,mịn d…</td><td>&quot;positive&quot;</td><td>&quot;sản phẩm sạch&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>46</td><td>2344</td><td>&quot;SỬ DỤNG DỄ DÀNG, RẤT THOẢI MÁI…</td><td>&quot;1/5/2023&quot;</td><td>&quot;20:04&quot;</td><td>5</td><td>308500004</td><td>&quot;sử dụng dễ dàng, rất thoải mái…</td><td>&quot;sử dụng dàng, thoải mái, thư g…</td><td>&quot;positive&quot;</td><td>&quot;sản phẩm thư giãn&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td></tr><tr><td>47</td><td>2893</td><td>&quot;Sản phẩm bao bì đẹp, thấm nhan…</td><td>&quot;1/2/2021&quot;</td><td>&quot;13:41&quot;</td><td>5</td><td>422202580</td><td>&quot;sản phẩm bao bì đẹp, thấm nhan…</td><td>&quot;sản phẩm bao bì đẹp, thấm nhan…</td><td>&quot;positive&quot;</td><td>&quot;sản phẩm tốt&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td></tr><tr><td>48</td><td>182</td><td>&quot;tẩy trang tốt, nhưng quà tặng …</td><td>&quot;28/05/2022&quot;</td><td>&quot;14:22&quot;</td><td>4</td><td>422204259</td><td>&quot;tẩy trang tốt, nhưng quà tặng …</td><td>&quot;tẩy trang tốt, quà tặng không …</td><td>&quot;positive&quot;</td><td>&quot;sản phẩm tốt&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td></tr><tr><td>49</td><td>3810</td><td>&quot;đây là lọ kem dưỡng ẩm mà tui …</td><td>&quot;14/05/2024&quot;</td><td>&quot;8:44&quot;</td><td>5</td><td>422209048</td><td>&quot;đây là lọ kem dưỡng ẩm mà tui …</td><td>&quot;lọ kem dưỡng ẩm tui xài hủ....…</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td></tr><tr><td>50</td><td>1637</td><td>&quot;Mình da khô, tuy nhiên dùng vi…</td><td>&quot;24/07/2024&quot;</td><td>&quot;11:32&quot;</td><td>5</td><td>100160022</td><td>&quot;mình da khô, tuy nhiên dùng vi…</td><td>&quot;da khô, nhiên vichy dưỡng ẫm s…</td><td>&quot;positive&quot;</td><td>&quot;sản phẩm nâng tông&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td><td>&quot;neutral&quot;</td><td>&quot;&quot;</td></tr></tbody></table></div>"]},"metadata":{},"execution_count":158}]},{"cell_type":"code","source":["result_df.filter(pl.col('giao_hang') == '\"negative\"')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98},"id":"kuJmAnTwln1D","executionInfo":{"status":"ok","timestamp":1733936674373,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nam Chan Nguyen","userId":"04673706717042935425"}},"outputId":"1df4263f-c8be-4002-9d2e-f07b918d2504"},"execution_count":159,"outputs":[{"output_type":"execute_result","data":{"text/plain":["shape: (0, 15)\n","┌─────┬─────────────┬─────────────┬────────────┬───┬─────────┬────────────┬───────────┬────────────┐\n","│ id  ┆ ma_khach_ha ┆ noi_dung_bi ┆ ngay_binh_ ┆ … ┆ dich_vu ┆ dich_vu_kw ┆ giao_hang ┆ giao_hang_ │\n","│ --- ┆ ng          ┆ nh_luan     ┆ luan       ┆   ┆ ---     ┆ ---        ┆ ---       ┆ kw         │\n","│ i64 ┆ ---         ┆ ---         ┆ ---        ┆   ┆ str     ┆ str        ┆ str       ┆ ---        │\n","│     ┆ i64         ┆ str         ┆ str        ┆   ┆         ┆            ┆           ┆ str        │\n","╞═════╪═════════════╪═════════════╪════════════╪═══╪═════════╪════════════╪═══════════╪════════════╡\n","└─────┴─────────────┴─────────────┴────────────┴───┴─────────┴────────────┴───────────┴────────────┘"],"text/html":["<div><style>\n",".dataframe > thead > tr,\n",".dataframe > tbody > tr {\n","  text-align: right;\n","  white-space: pre-wrap;\n","}\n","</style>\n","<small>shape: (0, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>ma_khach_hang</th><th>noi_dung_binh_luan</th><th>ngay_binh_luan</th><th>gio_binh_luan</th><th>so_sao</th><th>ma_san_pham</th><th>content_lower</th><th>cleaned_content</th><th>san_pham</th><th>san_pham_kw</th><th>dich_vu</th><th>dich_vu_kw</th><th>giao_hang</th><th>giao_hang_kw</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody></tbody></table></div>"]},"metadata":{},"execution_count":159}]},{"cell_type":"markdown","source":[],"metadata":{"id":"_TOrLe0h8bjd"}}]}