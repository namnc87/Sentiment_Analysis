import streamlit as st
import string
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from collections import Counter
import underthesea
from underthesea import word_tokenize, pos_tag, sent_tokenize
import re
import regex
import plotly.express as px
import polars as pl
from functools import lru_cache

# Cho 3 file csv nhu sau:

# San_pham.csv: chá»©a thÃ´ng tin sáº£n pháº©m thuá»™c nhÃ³m â€œChÄƒm sÃ³c da máº·tâ€ nhÆ° ma_san_pham, ten_san_pham, gia_ban, gia_goc, phan_loai, mo_ta, diem_trung_binh
# Khach_hang.csv: chá»©a thÃ´ng tin khÃ¡ch hÃ ng gá»“m ma_khach_hang,ho_ten
# Danh_gia.csv: chá»©a thÃ´ng tin Ä‘Ã¡nh giÃ¡ cá»§a khÃ¡ch hÃ ng cho sáº£n pháº©m gá»“m id, ma_khach_hang, noi_dung_binh_luan, ngay_binh_luan, gio_binh_luan, so_sao, ma_san_pham

#################### SET SIDEBAR, PAGE TITLE


st.set_page_config(page_title="Product Analysis", page_icon="ğŸ”")
st.title("ğŸ” PhÃ¢n tÃ­ch sáº£n pháº©m:")

st.sidebar.success("GiÃ¡o ViÃªn HÆ°á»›ng Dáº«n: \n # KHUáº¤T THUá»² PHÆ¯Æ NG")
st.sidebar.success("Há»c ViÃªn:\n # NGUYá»„N CHáº¤N NAM \n # CHáº¾ THá»Š ANH TUYá»€N")
st.sidebar.success("NgÃ y bÃ¡o cÃ¡o: \n # 16/12/2024")

################################ BIá»‚U Äá»’ Tá»”NG QUAN Vá»€ BÃŒNH LUáº¬N VÃ€ Sáº¢N PHáº¨M

# "C:/Users/Windows 10/Documents/Zalo Received Files/GUI_project1_Copy/GUI_project1_Copy/"

# Load data
san_pham = pd.read_csv('San_pham.csv')
danh_gia= pd.read_csv('Danh_gia.csv')
khach_hang= pd.read_csv('Khach_hang.csv')
san_pham_image_brand_link = pd.read_csv('San_pham_Link_Image_Brand.csv')

################ START_ Tien xu ly cot noi_dung_binh_luan #####################

#LOAD EMOJICON
file = open('emojicon.txt', 'r', encoding="utf8")
emoji_lst = file.read().split('\n')
emoji_dict = {}
for line in emoji_lst:
    key, value = line.split('\t')
    emoji_dict[key] = str(value)
file.close()
#################
#LOAD TEENCODE
file = open('teencode.txt', 'r', encoding="utf8")
teen_lst = file.read().split('\n')
teen_dict = {}
for line in teen_lst:
    key, value = line.split('\t')
    teen_dict[key] = str(value)
file.close()

with open("teencode.txt", 'r', encoding='utf-8') as file:
    for line in file:
        line = line.strip()  # Loáº¡i bá» khoáº£ng tráº¯ng á»Ÿ Ä‘áº§u vÃ  cuá»‘i dÃ²ng
        if line:  # Chá»‰ thá»±c hiá»‡n náº¿u dÃ²ng khÃ´ng trá»‘ng
            try:
                key, value = line.split('\t')
                # Tiáº¿n hÃ nh xá»­ lÃ½ key vÃ  value á»Ÿ Ä‘Ã¢y
            except ValueError:
                print(f'Line has an unexpected format: {line}')
###############
#LOAD TRANSLATE ENGLISH -> VNMESE
file = open('english-vnmese.txt', 'r', encoding="utf8")
english_lst = file.read().split('\n')
english_dict = {}
for line in english_lst:
    key, value = line.split('\t')
    english_dict[key] = str(value)
file.close()
################
#LOAD wrong words
file = open('wrong-word.txt', 'r', encoding="utf8")
wrong_lst = file.read().split('\n')
file.close()
#################
#LOAD STOPWORDS
file = open('vietnamese-stopwords.txt', 'r', encoding="utf8")
stop_words = file.read().split('\n')
file.close()

def process_text(text, emoji_dict, teen_dict, wrong_lst):
    document = text.lower()
    document = document.replace("â€™",'')
    document = regex.sub(r'\.+', ".", document)
    new_sentence =''
    for sentence in sent_tokenize(document):
        # if not(sentence.isascii()):
        ###### CONVERT EMOJICON
        sentence = ''.join(emoji_dict[word]+' ' if word in emoji_dict else word for word in list(sentence))
        ###### CONVERT TEENCODE
        sentence = ' '.join(teen_dict[word] if word in teen_dict else word for word in sentence.split())
        ###### DEL Punctuation & Numbers
        pattern = r'(?i)\b[a-zÃ¡Ã áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã©Ã¨áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã³Ã²á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£Ã­Ã¬á»‰Ä©á»‹ÃºÃ¹á»§Å©á»¥Æ°á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µÄ‘]+\b'
        sentence = ' '.join(regex.findall(pattern,sentence))
        # ...
        ###### DEL wrong words
        sentence = ' '.join('' if word in wrong_lst else word for word in sentence.split())
        new_sentence = new_sentence+ sentence + '. '
    document = new_sentence
    #print(document)
    ###### DEL excess blank space
    document = regex.sub(r'\s+', ' ', document).strip()
    #...
    return document


# Chuáº©n hÃ³a unicode tiáº¿ng viá»‡t
def loaddicchar():
    uniChars = "Ã Ã¡áº£Ã£áº¡Ã¢áº§áº¥áº©áº«áº­Äƒáº±áº¯áº³áºµáº·Ã¨Ã©áº»áº½áº¹Ãªá»áº¿á»ƒá»…á»‡Ä‘Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»“á»‘á»•á»—á»™Æ¡á»á»›á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»«á»©á»­á»¯á»±á»³Ã½á»·á»¹á»µÃ€Ãáº¢Ãƒáº Ã‚áº¦áº¤áº¨áºªáº¬Ä‚áº°áº®áº²áº´áº¶ÃˆÃ‰áººáº¼áº¸ÃŠá»€áº¾á»‚á»„á»†ÄÃŒÃá»ˆÄ¨á»ŠÃ’Ã“á»Ã•á»ŒÃ”á»’á»á»”á»–á»˜Æ á»œá»šá»á» á»¢Ã™Ãšá»¦Å¨á»¤Æ¯á»ªá»¨á»¬á»®á»°á»²Ãá»¶á»¸á»´Ã‚Ä‚ÄÃ”Æ Æ¯"
    unsignChars = "aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU"

    dic = {}
    char1252 = 'aÌ€|aÌ|aÌ‰|aÌƒ|aÌ£|Ã¢Ì€|Ã¢Ì|Ã¢Ì‰|Ã¢Ìƒ|Ã¢Ì£|ÄƒÌ€|ÄƒÌ|ÄƒÌ‰|ÄƒÌƒ|ÄƒÌ£|eÌ€|eÌ|eÌ‰|eÌƒ|eÌ£|ÃªÌ€|ÃªÌ|ÃªÌ‰|ÃªÌƒ|ÃªÌ£|iÌ€|iÌ|iÌ‰|iÌƒ|iÌ£|oÌ€|oÌ|oÌ‰|oÌƒ|oÌ£|Ã´Ì€|Ã´Ì|Ã´Ì‰|Ã´Ìƒ|Ã´Ì£|Æ¡Ì€|Æ¡Ì|Æ¡Ì‰|Æ¡Ìƒ|Æ¡Ì£|uÌ€|uÌ|uÌ‰|uÌƒ|uÌ£|Æ°Ì€|Æ°Ì|Æ°Ì‰|Æ°Ìƒ|Æ°Ì£|yÌ€|yÌ|yÌ‰|yÌƒ|yÌ£|AÌ€|AÌ|AÌ‰|AÌƒ|AÌ£|Ã‚Ì€|Ã‚Ì|Ã‚Ì‰|Ã‚Ìƒ|Ã‚Ì£|Ä‚Ì€|Ä‚Ì|Ä‚Ì‰|Ä‚Ìƒ|Ä‚Ì£|EÌ€|EÌ|EÌ‰|EÌƒ|EÌ£|ÃŠÌ€|ÃŠÌ|ÃŠÌ‰|ÃŠÌƒ|ÃŠÌ£|IÌ€|IÌ|IÌ‰|IÌƒ|IÌ£|OÌ€|OÌ|OÌ‰|OÌƒ|OÌ£|Ã”Ì€|Ã”Ì|Ã”Ì‰|Ã”Ìƒ|Ã”Ì£|Æ Ì€|Æ Ì|Æ Ì‰|Æ Ìƒ|Æ Ì£|UÌ€|UÌ|UÌ‰|UÌƒ|UÌ£|Æ¯Ì€|Æ¯Ì|Æ¯Ì‰|Æ¯Ìƒ|Æ¯Ì£|YÌ€|YÌ|YÌ‰|YÌƒ|YÌ£'.split(
        '|')
    charutf8 = "Ã |Ã¡|áº£|Ã£|áº¡|áº§|áº¥|áº©|áº«|áº­|áº±|áº¯|áº³|áºµ|áº·|Ã¨|Ã©|áº»|áº½|áº¹|á»|áº¿|á»ƒ|á»…|á»‡|Ã¬|Ã­|á»‰|Ä©|á»‹|Ã²|Ã³|á»|Ãµ|á»|á»“|á»‘|á»•|á»—|á»™|á»|á»›|á»Ÿ|á»¡|á»£|Ã¹|Ãº|á»§|Å©|á»¥|á»«|á»©|á»­|á»¯|á»±|á»³|Ã½|á»·|á»¹|á»µ|Ã€|Ã|áº¢|Ãƒ|áº |áº¦|áº¤|áº¨|áºª|áº¬|áº°|áº®|áº²|áº´|áº¶|Ãˆ|Ã‰|áºº|áº¼|áº¸|á»€|áº¾|á»‚|á»„|á»†|ÃŒ|Ã|á»ˆ|Ä¨|á»Š|Ã’|Ã“|á»|Ã•|á»Œ|á»’|á»|á»”|á»–|á»˜|á»œ|á»š|á»|á» |á»¢|Ã™|Ãš|á»¦|Å¨|á»¤|á»ª|á»¨|á»¬|á»®|á»°|á»²|Ã|á»¶|á»¸|á»´".split(
        '|')
    for i in range(len(char1252)):
        dic[char1252[i]] = charutf8[i]
    return dic

# ÄÆ°a toÃ n bá»™ dá»¯ liá»‡u qua hÃ m nÃ y Ä‘á»ƒ chuáº©n hÃ³a láº¡i
def covert_unicode(txt):
    dicchar = loaddicchar()
    return regex.sub(
        r'aÌ€|aÌ|aÌ‰|aÌƒ|aÌ£|Ã¢Ì€|Ã¢Ì|Ã¢Ì‰|Ã¢Ìƒ|Ã¢Ì£|ÄƒÌ€|ÄƒÌ|ÄƒÌ‰|ÄƒÌƒ|ÄƒÌ£|eÌ€|eÌ|eÌ‰|eÌƒ|eÌ£|ÃªÌ€|ÃªÌ|ÃªÌ‰|ÃªÌƒ|ÃªÌ£|iÌ€|iÌ|iÌ‰|iÌƒ|iÌ£|oÌ€|oÌ|oÌ‰|oÌƒ|oÌ£|Ã´Ì€|Ã´Ì|Ã´Ì‰|Ã´Ìƒ|Ã´Ì£|Æ¡Ì€|Æ¡Ì|Æ¡Ì‰|Æ¡Ìƒ|Æ¡Ì£|uÌ€|uÌ|uÌ‰|uÌƒ|uÌ£|Æ°Ì€|Æ°Ì|Æ°Ì‰|Æ°Ìƒ|Æ°Ì£|yÌ€|yÌ|yÌ‰|yÌƒ|yÌ£|AÌ€|AÌ|AÌ‰|AÌƒ|AÌ£|Ã‚Ì€|Ã‚Ì|Ã‚Ì‰|Ã‚Ìƒ|Ã‚Ì£|Ä‚Ì€|Ä‚Ì|Ä‚Ì‰|Ä‚Ìƒ|Ä‚Ì£|EÌ€|EÌ|EÌ‰|EÌƒ|EÌ£|ÃŠÌ€|ÃŠÌ|ÃŠÌ‰|ÃŠÌƒ|ÃŠÌ£|IÌ€|IÌ|IÌ‰|IÌƒ|IÌ£|OÌ€|OÌ|OÌ‰|OÌƒ|OÌ£|Ã”Ì€|Ã”Ì|Ã”Ì‰|Ã”Ìƒ|Ã”Ì£|Æ Ì€|Æ Ì|Æ Ì‰|Æ Ìƒ|Æ Ì£|UÌ€|UÌ|UÌ‰|UÌƒ|UÌ£|Æ¯Ì€|Æ¯Ì|Æ¯Ì‰|Æ¯Ìƒ|Æ¯Ì£|YÌ€|YÌ|YÌ‰|YÌƒ|YÌ£',
        lambda x: dicchar[x.group()], txt)


def process_special_word(text):
    # cÃ³ thá»ƒ cÃ³ nhiá»u tá»« Ä‘áº·c biá»‡t cáº§n rÃ¡p láº¡i vá»›i nhau
    new_text = ''
    text_lst = text.split()
    i= 0
    # khÃ´ng, cháº³ng, cháº£...
    if 'khÃ´ng' in text_lst:
        while i <= len(text_lst) - 1:
            word = text_lst[i]
            #print(word)
            #print(i)
            if  word == 'khÃ´ng':
                next_idx = i+1
                if next_idx <= len(text_lst) -1:
                    word = word +'_'+ text_lst[next_idx]
                i= next_idx + 1
            else:
                i = i+1
            new_text = new_text + word + ' '
    else:
        new_text = text
    return new_text.strip()

# HÃ m Ä‘á»ƒ chuáº©n hÃ³a cÃ¡c tá»« cÃ³ kÃ½ tá»± láº·p
def normalize_repeated_characters(text):
    # Thay tháº¿ má»i kÃ½ tá»± láº·p liÃªn tiáº¿p báº±ng má»™t kÃ½ tá»± Ä‘Ã³
    # VÃ­ dá»¥: "lÃ²nggggg" thÃ nh "lÃ²ng", "thiá»‡tttt" thÃ nh "thiá»‡t"
    return re.sub(r'(.)\1+', r'\1', text)


def find_words(document, list_of_words):
    document_lower = document.lower()
    word_count = 0
    word_list = []

    for word in list_of_words:
        if word in document_lower:
            print(word)
            word_count += document_lower.count(word)
            word_list.append(word)

    return word_count, word_list

def apply_processing(value):
    # Kiá»ƒm tra xem giÃ¡ trá»‹ cÃ³ pháº£i lÃ  chuá»—i khÃ´ng
    if isinstance(value, str):  # Chá»‰ xá»­ lÃ½ náº¿u value lÃ  string
        # Chuyá»ƒn Ä‘á»•i unicode
        text = covert_unicode(value)
        
        # Xá»­ lÃ½ tá»« Ä‘áº·c biá»‡t
        text = process_special_word(text)
        
        # Chuáº©n hÃ³a cÃ¡c kÃ½ tá»± láº·p
        text = normalize_repeated_characters(text)
        
        # Xá»­ lÃ½ vÄƒn báº£n
        text = process_text(text, emoji_dict, teen_dict, wrong_lst)
        
        return text
    else:
        # Náº¿u khÃ´ng pháº£i chuá»—i, cÃ³ thá»ƒ tráº£ vá» giÃ¡ trá»‹ máº·c Ä‘á»‹nh hoáº·c None
        return ''  



################ END_Tien xu ly cot noi_dung_binh_luan #####################

# HÃ m phÃ¢n loáº¡i dá»±a trÃªn giÃ¡ trá»‹ cá»§a cá»™t 'so_sao'
def classify_rating(star_rating):
    if star_rating <= 4:
        return 'negative'
    elif star_rating == 5:
        return 'positive'

# Ãp dá»¥ng hÃ m vÃ o cá»™t 'so_sao' Ä‘á»ƒ táº¡o cá»™t má»›i 'phan_loai_danh_gia'
danh_gia['phan_loai_danh_gia'] = danh_gia['so_sao'].apply(classify_rating)


san_pham = san_pham.merge(san_pham_image_brand_link,on="ma_san_pham", how='left')

danhgia_sanpham = danh_gia.merge(san_pham,on="ma_san_pham", how='left')
df=danhgia_sanpham.copy()
st.write(df)

#---START_HÃ m thá»‘ng káº¿ sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo thÃ¡ng----------------------------------------
def analyze_comments_by_month(df, product_id):
    """Thá»‘ng kÃª sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo thÃ¡ng cho má»™t sáº£n pháº©m."""
    
    # Chá»n ra bÃ¬nh luáº­n cá»§a sáº£n pháº©m cá»¥ thá»ƒ
    product_comments = df[df['ma_san_pham'] == product_id]
    
    # Chuyá»ƒn Ä‘á»•i cá»™t 'ngay_binh_luan' sang kiá»ƒu datetime
    product_comments['ngay_binh_luan'] = pd.to_datetime(product_comments['ngay_binh_luan'], format='%d/%m/%Y')
    product_comments.loc[:, 'month'] = product_comments['ngay_binh_luan'].dt.to_period('M')  # Láº¥y thÃ¡ng vÃ  nÄƒm

    # Thiáº¿t láº­p thÃ¡ng báº¯t Ä‘áº§u vÃ  thÃ¡ng káº¿t thÃºc vá»›i giÃ¡ trá»‹ máº·c Ä‘á»‹nh lÃ  thÃ¡ng nhá» nháº¥t vÃ  lá»›n nháº¥t
    min_month = product_comments['ngay_binh_luan'].min().to_period('M')
    max_month = product_comments['ngay_binh_luan'].max().to_period('M')
    
    st.write("**Chá»n khoáº£ng thá»i gian Ä‘á»ƒ xem bÃ¬nh luáº­n:**")
    
    # Táº¡o hai cá»™t cho Ã´ nháº­p thÃ¡ng báº¯t Ä‘áº§u vÃ  thÃ¡ng káº¿t thÃºc
    col1, col2 = st.columns(2)
    
    with col1:
        start_month = st.date_input('ThÃ¡ng báº¯t Ä‘áº§u:', value=min_month.to_timestamp(), key=f'start_month_{product_id}')
        
    with col2:
        end_month = st.date_input('ThÃ¡ng káº¿t thÃºc:', value=max_month.to_timestamp(), key=f'end_month_{product_id}')
    
    # Chuyá»ƒn Ä‘á»•i Ä‘áº¿n Ä‘á»‹nh dáº¡ng Timestamp Ä‘á»ƒ sá»­ dá»¥ng vá»›i to_period
    start_period = pd.to_datetime(start_month).to_period('M')
    end_period = pd.to_datetime(end_month).to_period('M')

    # Lá»c bÃ¬nh luáº­n trong khoáº£ng thá»i gian Ä‘Ã£ chá»n
    filtered_comments = product_comments[(product_comments['month'] >= start_period) & (product_comments['month'] <= end_period)]

    # Äáº¿m sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo thÃ¡ng
    monthly_counts = filtered_comments.groupby('month').size().reset_index(name='count')
    
    # Hiá»ƒn thá»‹ báº£ng thá»‘ng kÃª
    st.write(f"**II. Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo thÃ¡ng tá»« {start_period} Ä‘áº¿n {end_period} cho sáº£n pháº©m ID '{product_id}':**")

    # Trá»±c quan hÃ³a báº±ng matplotlib
    plt.figure(figsize=(10, 5))
    bars = plt.bar(monthly_counts['month'].astype(str), monthly_counts['count'], color='skyblue')
    plt.xlabel('ThÃ¡ng')
    plt.ylabel('Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n')
    plt.title(f"Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo thÃ¡ng cho sáº£n pháº©m ID {product_id}")
    plt.xticks(rotation=45)  # Xoay tiÃªu Ä‘á» trá»¥c hoÃ nh
    plt.grid(axis='y')

    # ThÃªm nhÃ£n sá»‘ liá»‡u lÃªn tá»«ng cá»™t trong biá»ƒu Ä‘á»“
    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width() / 2, yval, int(yval), va='bottom')  # va='bottom' Ä‘á»ƒ Ä‘áº·t nhÃ£n á»Ÿ trÃªn cá»™t

    # Hiá»ƒn thá»‹ Ä‘á»“ thá»‹ trong Streamlit
    st.pyplot(plt)

    if not monthly_counts.empty:
        # Lá»c bÃ¬nh luáº­n theo Ä‘Ã¡nh giÃ¡
        rating_counts = filtered_comments['so_sao'].value_counts().reindex(range(1, 6), fill_value=0).reset_index()
        rating_counts.columns = ['so_sao', 'count']
    
        # Hiá»ƒn thá»‹ tá»•ng sá»‘ lÆ°á»£ng bÃ¬nh luáº­n
        total_comments = filtered_comments.shape[0]
        st.write(f"**Tá»•ng sá»‘ bÃ¬nh luáº­n cÃ³ trong khoáº£ng thá»i gian Ä‘Ã£ chá»n: {total_comments} bÃ¬nh luáº­n.**")

        # Hiá»ƒn thá»‹ thá»‘ng kÃª Ä‘Ã¡nh giÃ¡
        st.write(f"**Thá»‘ng kÃª bÃ¬nh luáº­n theo Ä‘Ã¡nh giÃ¡ trong khoáº£ng thá»i gian tá»« {start_month} Ä‘áº¿n {end_month}:**")
    
        # Táº¡o cá»™t trong Streamlit Ä‘á»ƒ hiá»ƒn thá»‹ báº£ng vÃ  biá»ƒu Ä‘á»“ ngang nhau
        col1, col2 = st.columns([1, 2])  # Cá»™t 1 (báº£ng) 1 pháº§n, cá»™t 2 (biá»ƒu Ä‘á»“) 2 pháº§n
    
        # Hiá»ƒn thá»‹ báº£ng thá»‘ng kÃª trong cá»™t 1
        with col1:
            st.dataframe(rating_counts)
    
        # Trá»±c quan hÃ³a thá»‘ng kÃª Ä‘Ã¡nh giÃ¡ trong cá»™t 2
        with col2:
            plt.figure(figsize=(5, 5))  # Äiá»u chá»‰nh kÃ­ch thÆ°á»›c cá»§a biá»ƒu Ä‘á»“
            plt.bar(rating_counts['so_sao'].astype(str), rating_counts['count'], color='green')
            plt.xlabel('ÄÃ¡nh giÃ¡')
            plt.ylabel('Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n')
            plt.title(f"Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo Ä‘Ã¡nh giÃ¡ tá»« {start_month} Ä‘áº¿n {end_month} cho sáº£n pháº©m ID {product_id}")
            plt.xticks(rating_counts['so_sao'].astype(str))  # Äáº£m báº£o táº¥t cáº£ cÃ¡c Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c hiá»ƒn thá»‹
            plt.grid(axis='y')
            st.pyplot(plt)

            # Close the figure to free memory
            plt.close()
    
        # Táº¡o tab cho tá»«ng loáº¡i Ä‘Ã¡nh giÃ¡
        st.write("**Chi tiáº¿t bÃ¬nh luáº­n theo Ä‘Ã¡nh giÃ¡:**")
        tabs = st.tabs([f"ÄÃ¡nh giÃ¡ {i}" for i in range(1, 6)])  # Táº¡o 5 tab cho cÃ¡c loáº¡i Ä‘Ã¡nh giÃ¡ tá»« 1 Ä‘áº¿n 5

        for i in range(1, 6):
            with tabs[i-1]:
                comments_for_rating = filtered_comments[filtered_comments['so_sao'] == i]
                if not comments_for_rating.empty:
                    st.write(f"**Chi tiáº¿t bÃ¬nh luáº­n cho Ä‘Ã¡nh giÃ¡ {i} sao:**")
                    st.dataframe(comments_for_rating[['ngay_binh_luan', 'noi_dung_binh_luan']], use_container_width=True)
                    st.write(comments_for_rating)
                    
                    # Thá»‘ng kÃª cho tá»«ng cá»™t
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.write("**Thá»‘ng kÃª Sáº£n pháº©m:**")
                        pos_data = comments_for_rating[comments_for_rating['san_pham'] == 'positive']
                        neg_data = comments_for_rating[comments_for_rating['san_pham'] == 'negative']
                        pos_count = len(pos_data)
                        neg_count = len(neg_data)
                        st.write(f"- Positive: {pos_count}")
                        st.write(f"- Negative: {neg_count}")
                        
                        # WordCloud cho positive
                        if pos_count > 0:
                            pos_wordcloud = create_wordcloud(pos_data['noi_dung_binh_luan'].tolist(), 'Positive Words')
                            if pos_wordcloud:
                                st.pyplot(pos_wordcloud)
                        
                        # WordCloud cho negative
                        if neg_count > 0:
                            neg_wordcloud = create_wordcloud(neg_data['noi_dung_binh_luan'].tolist(), 'Negative Words')
                            if neg_wordcloud:
                                st.pyplot(neg_wordcloud)
                    
                    with col2:
                        st.write("**Thá»‘ng kÃª Dá»‹ch vá»¥:**")
                        pos_data = comments_for_rating[comments_for_rating['dich_vu'] == 'positive']
                        neg_data = comments_for_rating[comments_for_rating['dich_vu'] == 'negative']
                        pos_count = len(pos_data)
                        neg_count = len(neg_data)
                        st.write(f"- Positive: {pos_count}")
                        st.write(f"- Negative: {neg_count}")
                        
                        # WordCloud cho positive
                        if pos_count > 0:
                            pos_wordcloud = create_wordcloud(pos_data['noi_dung_binh_luan'].tolist(), 'Positive Words')
                            if pos_wordcloud:
                                st.pyplot(pos_wordcloud)
                        
                        # WordCloud cho negative
                        if neg_count > 0:
                            neg_wordcloud = create_wordcloud(neg_data['noi_dung_binh_luan'].tolist(), 'Negative Words')
                            if neg_wordcloud:
                                st.pyplot(neg_wordcloud)
                    
                    with col3:
                        st.write("**Thá»‘ng kÃª Giao hÃ ng:**")
                        pos_data = comments_for_rating[comments_for_rating['giao_hang'] == 'positive']
                        neg_data = comments_for_rating[comments_for_rating['giao_hang'] == 'negative']
                        pos_count = len(pos_data)
                        neg_count = len(neg_data)
                        st.write(f"- Positive: {pos_count}")
                        st.write(f"- Negative: {neg_count}")
                        
                        # WordCloud cho positive
                        if pos_count > 0:
                            pos_wordcloud = create_wordcloud(pos_data['noi_dung_binh_luan'].tolist(), 'Positive Words')
                            if pos_wordcloud:
                                st.pyplot(pos_wordcloud)
                        
                        # WordCloud cho negative
                        if neg_count > 0:
                            neg_wordcloud = create_wordcloud(neg_data['noi_dung_binh_luan'].tolist(), 'Negative Words')
                            if neg_wordcloud:
                                st.pyplot(neg_wordcloud)
                        
                else:
                    st.write(f"KhÃ´ng cÃ³ bÃ¬nh luáº­n nÃ o cho Ä‘Ã¡nh giÃ¡ {i} sao.")
        
        # Äá»ƒ giá»¯ cho chiá»u cao cá»™t cÃ¢n báº±ng, táº¡o má»™t dÃ²ng trá»‘ng báº±ng cÃ¡ch sá»­ dá»¥ng `st.empty()`.
        st.empty()  # Giá»¯ khÃ´ng gian cho chiá»u cao báº±ng nhau
    else:
        st.write(f"KhÃ´ng cÃ³ bÃ¬nh luáº­n nÃ o trong khoáº£ng thá»i gian tá»« {start_period} Ä‘áº¿n {end_period}.")

#----------------------------------------END_HÃ m thá»‘ng káº¿ sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo thÃ¡ng---

#---START_HÃ m thá»‘ng káº¿ sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo giá»-------------------------------
def analyze_comments_by_hour(df, product_id):
    """Thá»‘ng kÃª sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo khung giá» trong ngÃ y cho má»™t sáº£n pháº©m."""
    
    # Chá»n ra bÃ¬nh luáº­n cá»§a sáº£n pháº©m cá»¥ thá»ƒ
    product_comments = df.loc[df['ma_san_pham'] == product_id].copy()
    
    # Chuyá»ƒn Ä‘á»•i cá»™t 'gio_binh_luan' sang kiá»ƒu datetime Ä‘á»ƒ láº¥y giá»
    product_comments['gio_binh_luan'] = product_comments['gio_binh_luan'].astype(str)
    product_comments.loc[:, 'hour'] = pd.to_datetime(product_comments['gio_binh_luan'], format='%H:%M').dt.hour

    # Thiáº¿t láº­p giá» báº¯t Ä‘áº§u vÃ  giá» káº¿t thÃºc vá»›i giÃ¡ trá»‹ máº·c Ä‘á»‹nh lÃ  giá» nhá» nháº¥t vÃ  lá»›n nháº¥t
    min_hour = int(product_comments['hour'].min())  # Chuyá»ƒn vá» kiá»ƒu int
    max_hour = int(product_comments['hour'].max())  # Chuyá»ƒn vá» kiá»ƒu int
    
    st.write("**Chá»n khoáº£ng thá»i gian (giá») Ä‘á»ƒ xem bÃ¬nh luáº­n:**")
    
    # Táº¡o hai cá»™t cho Ã´ nháº­p giá» báº¯t Ä‘áº§u vÃ  giá» káº¿t thÃºc
    col1, col2 = st.columns(2)

    with col1:
        start_hour = st.selectbox('Giá» báº¯t Ä‘áº§u:', range(min_hour, max_hour + 1), index=0, key=f'start_hour_{product_id}')  # Unique key
    
    with col2:
        end_hour = st.selectbox('Giá» káº¿t thÃºc:', range(min_hour, max_hour + 1), index=max_hour - min_hour, key=f'end_hour_{product_id}')  # Unique key
    
    # Lá»c bÃ¬nh luáº­n trong khoáº£ng thá»i gian Ä‘Ã£ chá»n
    filtered_comments = product_comments[(product_comments['hour'] >= start_hour) & (product_comments['hour'] <= end_hour)]

    # Äáº¿m sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo giá»
    hourly_counts = filtered_comments.groupby('hour').size().reset_index(name='count')

    # Hiá»ƒn thá»‹ báº£ng thá»‘ng kÃª
    st.write(f"**II. Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo giá» tá»« {start_hour}:00 Ä‘áº¿n {end_hour}:00 cho sáº£n pháº©m ID '{product_id}':**")

    # Trá»±c quan hÃ³a báº±ng matplotlib
    plt.figure(figsize=(10, 5))
    if not hourly_counts.empty:
        bars = plt.bar(hourly_counts['hour'], hourly_counts['count'], color='skyblue')
        plt.xlabel('Khung giá» trong ngÃ y')
        plt.ylabel('Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n')
        plt.title(f"Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo khung giá» cho sáº£n pháº©m ID {product_id}")
        plt.xticks(hourly_counts['hour'])  # Äáº£m báº£o táº¥t cáº£ cÃ¡c giá» Ä‘Æ°á»£c hiá»ƒn thá»‹
        plt.grid(axis='y')

        # ThÃªm nhÃ£n sá»‘ liá»‡u lÃªn tá»«ng cá»™t trong biá»ƒu Ä‘á»“
        for bar in bars:
            yval = bar.get_height()
            plt.text(bar.get_x() + bar.get_width() / 2, yval, int(yval), va='bottom')  # va='bottom' Ä‘á»ƒ Ä‘áº·t nhÃ£n á»Ÿ trÃªn cá»™t

        # Hiá»ƒn thá»‹ Ä‘á»“ thá»‹ trong Streamlit
        st.pyplot(plt)

        # Náº¿u cÃ³ bÃ¬nh luáº­n trong khoáº£ng thá»i gian Ä‘Ã£ chá»n, hiá»ƒn thá»‹ chi tiáº¿t
        if not filtered_comments.empty:
            # st.write(f"**Chi tiáº¿t bÃ¬nh luáº­n trong khung giá» tá»« {start_hour}:00 Ä‘áº¿n {end_hour}:00:**")
            # st.dataframe(filtered_comments[['gio_binh_luan', 'noi_dung_binh_luan', 'so_sao']])

            # Thá»‘ng kÃª sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo Ä‘Ã¡nh giÃ¡
            rating_counts = filtered_comments['so_sao'].value_counts().reindex(range(1, 6), fill_value=0).reset_index()
            rating_counts.columns = ['so_sao', 'count']

            # Hiá»ƒn thá»‹ tá»•ng sá»‘ lÆ°á»£ng bÃ¬nh luáº­n
            total_comments = filtered_comments.shape[0]
            st.write(f"**Tá»•ng sá»‘ bÃ¬nh luáº­n cÃ³ trong khoáº£ng thá»i gian Ä‘Ã£ chá»n: {total_comments} bÃ¬nh luáº­n.**")

            # Hiá»ƒn thá»‹ thá»‘ng kÃª Ä‘Ã¡nh giÃ¡
            st.write(f"**Thá»‘ng kÃª bÃ¬nh luáº­n theo Ä‘Ã¡nh giÃ¡ tá»« {start_hour}:00 Ä‘áº¿n {end_hour}:00:**")
            
            # Táº¡o cá»™t trong Streamlit Ä‘á»ƒ hiá»ƒn thá»‹ báº£ng vÃ  biá»ƒu Ä‘á»“ ngang nhau
            col1, col2 = st.columns([1, 2])  # Cá»™t 1 (báº£ng) 1 pháº§n, cá»™t 2 (biá»ƒu Ä‘á»“) 2 pháº§n

            # Hiá»ƒn thá»‹ báº£ng thá»‘ng kÃª trong cá»™t 1
            with col1:
                st.dataframe(rating_counts)

            # Trá»±c quan hÃ³a thá»‘ng kÃª Ä‘Ã¡nh giÃ¡ trong cá»™t 2
            with col2:
                plt.figure(figsize=(5, 5))  # Äiá»u chá»‰nh kÃ­ch thÆ°á»›c cá»§a biá»ƒu Ä‘á»“
                plt.bar(rating_counts['so_sao'].astype(str), rating_counts['count'], color='green')
                plt.xlabel('ÄÃ¡nh giÃ¡')
                plt.ylabel('Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n')
                plt.title(f"Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo Ä‘Ã¡nh giÃ¡ tá»« {start_hour}:00 Ä‘áº¿n {end_hour}:00 cho sáº£n pháº©m ID {product_id}")
                plt.xticks(rating_counts['so_sao'].astype(str))  # Äáº£m báº£o táº¥t cáº£ cÃ¡c Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c hiá»ƒn thá»‹
                plt.grid(axis='y')
                st.pyplot(plt)

            # Táº¡o tab cho tá»«ng loáº¡i Ä‘Ã¡nh giÃ¡
            st.write("**Chi tiáº¿t bÃ¬nh luáº­n theo Ä‘Ã¡nh giÃ¡:**")
            tabs = st.tabs([f"ÄÃ¡nh giÃ¡ {i}" for i in range(1, 6)])  # Táº¡o 5 tab cho cÃ¡c loáº¡i Ä‘Ã¡nh giÃ¡ tá»« 1 Ä‘áº¿n 5

            for i in range(1, 6):
                with tabs[i-1]:
                    comments_for_rating = filtered_comments[filtered_comments['so_sao'] == i]
                    if not comments_for_rating.empty:
                        st.write(f"**Chi tiáº¿t bÃ¬nh luáº­n cho Ä‘Ã¡nh giÃ¡ {i} sao:**")
                        st.dataframe(comments_for_rating[['gio_binh_luan', 'noi_dung_binh_luan']], use_container_width=True)
                    else:
                        st.write(f"KhÃ´ng cÃ³ bÃ¬nh luáº­n nÃ o cho Ä‘Ã¡nh giÃ¡ {i} sao.")

            # Äá»ƒ giá»¯ cho chiá»u cao cá»™t cÃ¢n báº±ng, táº¡o má»™t dÃ²ng trá»‘ng báº±ng cÃ¡ch sá»­ dá»¥ng `st.empty()`.
            st.empty()
        else:
            st.write(f"KhÃ´ng cÃ³ bÃ¬nh luáº­n nÃ o trong khoáº£ng thá»i gian tá»« {start_hour}:00 Ä‘áº¿n {end_hour}:00.")
    else:
        st.write(f"KhÃ´ng cÃ³ bÃ¬nh luáº­n nÃ o trong khoáº£ng thá»i gian tá»« {start_hour}:00 Ä‘áº¿n {end_hour}:00.")

#----------------------------------------END_HÃ m thá»‘ng káº¿ sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo giá»---

#---START_HÃ m thá»‘ng káº¿ sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo loáº¡i sao-------------------------------
def plot_star_ratings(danh_gia, user_input_int):
    # Chuyá»ƒn Ä‘á»•i user_input_int sang kiá»ƒu int náº¿u cáº§n
    user_input_int = str(user_input_int)
    
    # Thá»‘ng kÃª sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ theo tá»«ng sao
    star_ratings_count = danh_gia[danh_gia['ma_san_pham'] == user_input_int]['so_sao'].value_counts().sort_index()
    
    # Äáº£m báº£o cÃ³ Ä‘á»§ cÃ¡c má»©c sao tá»« 1 Ä‘áº¿n 5
    full_star_ratings = pd.Series([0] * 5, index=range(1, 6))
    full_star_ratings.update(star_ratings_count)
    
    # Hiá»ƒn thá»‹ thÃ´ng tin trÃªn Streamlit
    st.write(f"**III. Sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ theo tá»«ng sao cá»§a sáº£n pháº©m ID '{user_input_int}':**")

    # Táº¡o biá»ƒu Ä‘á»“ dáº¡ng cá»™t vá»›i matplotlib
    fig, ax = plt.subplots()
    ax.bar(full_star_ratings.index, full_star_ratings.values, color='skyblue')
    ax.set_title('Sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ theo tá»«ng sao')
    ax.set_xlabel('Sao')
    ax.set_ylabel('Sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡')
    ax.set_xticks(range(1, 6))

    # ThÃªm nhÃ£n cho cÃ¡c cá»™t
    for i, v in enumerate(full_star_ratings.values, start=1):
        ax.text(i, v, str(v), ha='center', va='bottom')

    # Trá»±c quan hÃ³a biá»ƒu Ä‘á»“ trong Streamlit
    st.pyplot(fig)

    st.write("Chi tiáº¿t Ä‘Ã¡nh giÃ¡")
    # Táº¡o tabs Ä‘á»ƒ hiá»ƒn thá»‹ bÃ¬nh luáº­n theo má»©c sao
    tabs = st.tabs([f"{star} Sao" for star in range(1, 6)])
    
    for star, tab in zip(range(1, 6), tabs):
        with tab:
            # Lá»c bÃ¬nh luáº­n theo sao
            comments_df = danh_gia[(danh_gia['ma_san_pham'] == user_input_int) & (danh_gia['so_sao'] == star)]
            # Hiá»ƒn thá»‹ bÃ¬nh luáº­n dÆ°á»›i dáº¡ng báº£ng
            st.write(f"BÃ¬nh luáº­n {star} Sao:")
            st.dataframe(comments_df[['noi_dung_binh_luan']],hide_index=True,width=1000)
#---------------------------------------END_HÃ m thá»‘ng káº¿ sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo loáº¡i sao--

#---START_HÃ m váº½ wordcloud bÃ¬nh luáº­n theo sáº£n pháº©m-------------------------------
def plot_product_comments_wordcloud(df, product_id, stopwords=None):
    """Váº½ Word Cloud cho bÃ¬nh luáº­n cá»§a sáº£n pháº©m cá»¥ thá»ƒ vá»›i cÃ¡c tab riÃªng biá»‡t cho tá»« tÃ­ch cá»±c vÃ  tiÃªu cá»±c."""
    
    # Lá»c bÃ¬nh luáº­n cá»§a sáº£n pháº©m cá»¥ thá»ƒ
    product_comments = df[df['ma_san_pham'] == product_id]['noi_dung_binh_luan']

    # Chuyá»ƒn Ä‘á»•i bÃ¬nh luáº­n thÃ nh danh sÃ¡ch, loáº¡i bá» NaN
    product_comments = product_comments.dropna().astype(str).tolist()

    # Láº¥y cÃ¡c tá»« tÃ­ch cá»±c vÃ  tiÃªu cá»±c tá»« file
    try:
        with open("positive_words.txt", 'r', encoding='utf-8') as f:
            positive_words = f.read().splitlines()
        
        with open("negative_words.txt", 'r', encoding='utf-8') as f:
            negative_words = f.read().splitlines()
        
        # Láº¥y stopwords náº¿u cÃ³
        if stopwords is None:
            stopwords = set()
        
        with open("vietnamese-stopwords.txt", 'r', encoding='utf-8') as f:
            stopwords.update(f.read().splitlines())
    
    except FileNotFoundError as e:
        st.error(f"KhÃ´ng tÃ¬m tháº¥y file: {e.filename}. HÃ£y kiá»ƒm tra Ä‘Æ°á»ng dáº«n!")
        return

    # Táº¡o slider cho sá»‘ lÆ°á»£ng tá»« hiá»ƒn thá»‹ trong Word Cloud
    num_words = st.slider("**Chá»n sá»‘ lÆ°á»£ng tá»« hiá»ƒn thá»‹:**", min_value=1, max_value=100, value=10, key=f'wordcloud_slider_{product_id}')

    # Táº¡o tabs cho wordcloud
    tabs = st.tabs(["Tá»« TÃ­ch Cá»±c", "Tá»« TiÃªu Cá»±c"])

    # Táº¡o hÃ m Ä‘á»ƒ váº½ Word Cloud tá»« danh sÃ¡ch cá»¥m tá»«
    def create_wordcloud(phrases):
        if phrases:
            # Táº¡o tá»« Ä‘iá»ƒn táº§n suáº¥t cho cÃ¡c cá»¥m tá»«
            freq_dict = {phrase: phrases.count(phrase) for phrase in set(phrases)}
            
            # Táº¡o WordCloud vá»›i collocations=False Ä‘á»ƒ giá»¯ nguyÃªn cá»¥m tá»«
            wordcloud = WordCloud(width=800, height=400,
                                background_color='white',
                                stopwords=stopwords,
                                max_words=num_words,
                                collocations=False).generate_from_frequencies(freq_dict)
            
            plt.figure(figsize=(10, 5))
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            st.pyplot(plt)
        else:
            st.write("KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ hiá»ƒn thá»‹ Word Cloud.")

    # Táº¡o Word Cloud cho tá»« tÃ­ch cá»±c trong tab Tá»« TÃ­ch Cá»±c
    with tabs[0]:
        st.subheader("Word Cloud cho Tá»« TÃ­ch Cá»±c")
        found_positive_phrases = []

        for positive_phrase in positive_words:
            if any(positive_phrase in comment for comment in product_comments):
                found_positive_phrases.append(positive_phrase)

        if found_positive_phrases:
            st.write("CÃ¡c cá»¥m tá»« tÃ­ch cá»±c tÃ¬m tháº¥y:", ', '.join(found_positive_phrases))
            create_wordcloud(found_positive_phrases)
        else:
            st.write("KhÃ´ng cÃ³ tá»« tÃ­ch cá»±c nÃ o Ä‘Æ°á»£c tÃ¬m tháº¥y.")

    # Táº¡o Word Cloud cho tá»« tiÃªu cá»±c trong tab Tá»« TiÃªu Cá»±c
    with tabs[1]:
        st.subheader("Word Cloud cho Tá»« TiÃªu Cá»±c")
        found_negative_phrases = []

        for negative_phrase in negative_words:
            if any(negative_phrase in comment for comment in product_comments):
                found_negative_phrases.append(negative_phrase)

        if found_negative_phrases:
            st.write("CÃ¡c cá»¥m tá»« tiÃªu cá»±c tÃ¬m tháº¥y:", ', '.join(found_negative_phrases))
            create_wordcloud(found_negative_phrases)
        else:
            st.write("KhÃ´ng cÃ³ tá»« tiÃªu cá»±c nÃ o Ä‘Æ°á»£c tÃ¬m tháº¥y.")
#----------------------------------------END_HÃ m váº½ wordcloud bÃ¬nh luáº­n theo sáº£n pháº©m---

# ----START_HÃ m chuyá»ƒn Ä‘á»•i Ä‘Æ¡n vá»‹ tiá»n tá»‡ VND--------------------
def format_currency(value):
    return f"{value:,.0f} VND"
# -----------------------------END_HÃ m chuyá»ƒn Ä‘á»•i Ä‘Æ¡n vá»‹ tiá»n tá»‡ VND---


# ------------START_HÃ m Ä‘á»ƒ thá»‘ng kÃª sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ theo thÆ°Æ¡ng hiá»‡u vÃ  loáº¡i Ä‘Ã¡nh giÃ¡--------------------
def analyze_product_reviews(df, selected_brands, review_type):
    filtered_df = df[df['thuong_hieu'].isin(selected_brands)]
    review_counts = filtered_df[filtered_df['so_sao'] == review_type].groupby('thuong_hieu').size()
    return review_counts
# ------------END_HÃ m Ä‘á»ƒ thá»‘ng kÃª sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ theo thÆ°Æ¡ng hiá»‡u vÃ  loáº¡i Ä‘Ã¡nh giÃ¡--------------------


@lru_cache(maxsize=None)
def load_keywords(filename):
    keywords = {}
    with open(filename, 'r', encoding='utf-8') as f:
        for line in f:
            if ':' in line:
                key, values = line.strip().split(':')
                keywords[key.strip()] = set(v.strip() for v in values.split(','))
    return keywords



def check_content_pandas(df: pd.DataFrame, category: str, keywords: dict, stop_words: set) -> pd.DataFrame:
    # Extract keywords from the keywords dictionary
    key_phrases = keywords['key_phrases']
    positive_words = set(keywords['positive_words'])  # Use set for faster lookup
    negative_words = set(keywords['negative_words'])
    
    # Convert content to lowercase
    df['content_lower'] = df['noi_dung_binh_luan'].str.lower()

    # Remove stop words and create cleaned content
    df['cleaned_content'] = df['content_lower'].astype(str).apply(
        lambda x: ' '.join([word for word in x.split() if word not in stop_words])
    )
    
    # Initialize lists for results
    sentiment_col = []
    keyword_col = []

    # Iterate over each row in the DataFrame
    for index, row in df.iterrows():
        found = False
        
        # Check if cleaned_content is None or empty
        cleaned_content = row['cleaned_content'] or '' 
        
        for phrase in key_phrases:
            if phrase in cleaned_content:
                # Check negative words first
                for neg_word in negative_words:
                    if neg_word in cleaned_content:
                        sentiment_col.append('negative')
                        keyword_col.append(f'{phrase} {neg_word}')
                        found = True
                        break  # Break out of the negative check
                if found:  # If already found a negative word, no need to check further
                    break
                
                # If no negatives, check for positives
                for pos_word in positive_words:
                    if pos_word in cleaned_content:
                        sentiment_col.append('positive')
                        keyword_col.append(f'{phrase} {pos_word}')
                        found = True
                        break
                if found:
                    break  # Break out if we've found a sentiment
        
        if not found:
            # No phrases found or no sentiment detected; check based on the category
            if category == 'san_pham':
                # Check for any negative word in the entire cleaned content
                for neg_word in negative_words:
                    if neg_word in cleaned_content:
                        sentiment_col.append('negative')
                        keyword_col.append(f'sáº£n pháº©m {neg_word}')
                        found = True
                        break

                if not found:
                    # Check for positive words
                    for pos_word in positive_words:
                        if pos_word in cleaned_content:
                            sentiment_col.append('positive')
                            keyword_col.append(f'sáº£n pháº©m {pos_word}')
                            found = True
                            break

            if not found:  # If nothing matched, it's neutral
                sentiment_col.append('neutral')
                keyword_col.append('')
    
    # Add the results to the DataFrame
    df[f"{category}"] = sentiment_col
    df[f"{category}_kw"] = keyword_col
    
    return df


def analyze_comments(df: pl.DataFrame) -> pl.DataFrame:
    # Load keywords for each type
    san_pham_kw = load_keywords('san_pham_keywords.txt')
    dich_vu_kw = load_keywords('dich_vu_keywords.txt')
    giao_hang_kw = load_keywords('giao_hang_keywords.txt')

    with open('vietnamese-stopwords.txt', 'r', encoding='utf-8') as file:
        stop_words = set(file.read().splitlines())  
    
    # Process each category and extend DataFrame accordingly
    df = check_content_pandas(df, 'san_pham', san_pham_kw, stop_words)
    df = check_content_pandas(df, 'dich_vu', dich_vu_kw, stop_words)
    df = check_content_pandas(df, 'giao_hang', giao_hang_kw, stop_words)
        
    return df



# PhÃ¢n tÃ­ch comments
danh_gia = analyze_comments(danh_gia) 




def create_wordcloud(text_data, title):
    if not text_data:  # Náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u
        return None
        
    # Táº¡o WordCloud (Ä‘Ã£ bá» font_path)
    wordcloud = WordCloud(
        width=300,
        height=200,
        background_color='white',
        max_words=10
    ).generate(' '.join(text_data))
    
    # Táº¡o figure
    fig, ax = plt.subplots(figsize=(4, 3))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    ax.set_title(title)
    return fig




def get_unique_brands(df):
    """Get unique brands from DataFrame."""
    brands = df['thuong_hieu'].astype(str).unique().tolist()
    return sorted([brand for brand in brands if brand.lower() != 'nan'])

def visualize_rating_counts(rating_counts, title):
    """Visualize rating counts with a horizontal bar chart."""
    plt.figure(figsize=(10, 5))
    bars = plt.barh(rating_counts['ten_san_pham'], rating_counts['tong_danh_gia'], color='skyblue')
    for bar in bars:
        plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, 
                 f'{int(bar.get_width())}', va='center')
    plt.xlabel('Sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡')
    plt.title(title)
    plt.tight_layout()
    st.pyplot(plt)


def plot_sentiment_distribution(sentiment_by_line):
    """Plot pie charts for sentiment distribution across product lines."""
    num_cols = 2
    cols = st.columns(num_cols)

    for idx, (dong_sp, row) in enumerate(sentiment_by_line.iterrows()):
        col_idx = idx % num_cols
        with cols[col_idx]:
            fig = px.pie(values=row.values,
                         names=row.index,
                         title=f'PhÃ¢n bá»‘ bÃ¬nh luáº­n - {dong_sp}',
                         color_discrete_map={'positive': '#2ECC71', 'negative': '#E74C3C'})
            fig.update_traces(textposition='inside', textinfo='percent+value', hole=.3)
            fig.update_layout(showlegend=True, height=300, width=300)
            st.plotly_chart(fig)



def format_product_selection(filtered_df):
    """Format the product selection list for dropdown."""
    return filtered_df.apply(lambda x: f"{x['ten_san_pham']} (Code: {x['ma_san_pham']})", axis=1).tolist()

def display_product_info(selected_row):
    """Display the product's information in the Streamlit app."""
    formatted_price = format_currency(selected_row['gia_ban'])
    
    col1, col2 = st.columns([2, 1.5])  # Adjust the weights as needed
    
    with col1:
        st.image(selected_row['hinh_anh'], caption=selected_row['ten_san_pham'])
    
    with col2:
        st.markdown(f"<h4>GiÃ¡ bÃ¡n: {formatted_price}</h4>", unsafe_allow_html=True)
        st.markdown(f"<h4>Äiá»ƒm trung bÃ¬nh: {selected_row['diem_trung_binh']}</h4>", unsafe_allow_html=True)
        st.page_link(page=selected_row['chi_tiet'], label='**Nháº¥n vÃ o Ä‘á»ƒ xem chi tiáº¿t**')

def display_analysis_tabs(selected_code):
    """Create and display tabs for product analysis."""
    analysis_tabs = st.tabs(['ThÃ¡ng', 'Giá»', 'WordCloud'])
    with analysis_tabs[0]:
        analyze_comments_by_month(danh_gia, selected_code)
    with analysis_tabs[1]:   
        analyze_comments_by_hour(danh_gia, selected_code)
    with analysis_tabs[2]:
        plot_product_comments_wordcloud(danh_gia, selected_code)



def prepare_data(df):
    """Pre-process data: Convert date and time columns and filter necessary columns."""
    df = df.copy()
    df['ngay_binh_luan'] = pd.to_datetime(df['ngay_binh_luan'], format='%d/%m/%Y', errors='coerce')
    df.dropna(subset=['ngay_binh_luan'], inplace=True)
    df['month'] = df['ngay_binh_luan'].dt.to_period('M')
    df['hour'] = pd.to_datetime(df['gio_binh_luan'].astype(str), format='%H:%M').dt.hour
    df['dong_san_pham'] = df['dong_san_pham'].astype(str)
    return df

@st.cache_data
def filter_data(df, selected_params):
    """Filter DataFrame based on selected parameters."""
    mask = (
        df['dong_san_pham'].isin(selected_params['dong_san_pham']) &
        df['thuong_hieu'].isin(selected_params['brands']) &
        df['so_sao'].isin(selected_params['review_types']) &
        (df['month'] >= pd.to_datetime(selected_params['start_month']).to_period('M')) &
        (df['month'] <= pd.to_datetime(selected_params['end_month']).to_period('M')) &
        (df['hour'] >= selected_params['start_hour']) &
        (df['hour'] <= selected_params['end_hour'])
    )
    return df[mask]

@st.cache_data
def create_bar_chart(filtered_df):
    """Create a bar chart of review counts by brand and review type."""
    review_counts = filtered_df.groupby(['thuong_hieu', 'so_sao']).size().unstack(fill_value=0)
    
    fig, ax = plt.subplots(figsize=(10, 6))
    review_counts.plot(kind='bar', width=0.8, ax=ax)
    for container in ax.containers:
        ax.bar_label(container, padding=3)
        
    ax.set_title('Sá»‘ lÆ°á»£ng ÄÃ¡nh giÃ¡ theo ThÆ°Æ¡ng hiá»‡u vÃ  Loáº¡i ÄÃ¡nh giÃ¡')
    ax.set_xlabel('ThÆ°Æ¡ng hiá»‡u')
    ax.set_ylabel('Sá»‘ lÆ°á»£ng ÄÃ¡nh giÃ¡')
    ax.tick_params(axis='x', rotation=45)
    ax.legend(title='Loáº¡i ÄÃ¡nh giÃ¡')
    
    return fig, review_counts

@st.cache_data
def create_pie_chart(review_counts, review_type):
    """Create a pie chart for the specific review type."""
    fig, ax = plt.subplots(figsize=(8, 8))
    review_counts[review_type].plot(kind='pie', autopct='%1.1f%%', startangle=90, ax=ax)
    ax.set_title(f'Tá»· lá»‡ Ä‘Ã¡nh giÃ¡ {review_type} sao giá»¯a cÃ¡c thÆ°Æ¡ng hiá»‡u')
    ax.set_ylabel('')
    
    return fig


# ------------START_ Main Streamlit App--------------------
# Táº¡o giao diá»‡n tÃ¬m kiáº¿m sáº£n pháº©m
st.title("TÃ¬m Kiáº¿m Sáº£n Pháº©m")

# Convert relevant columns to string, handling possible None values
df['ma_san_pham'] = df['ma_san_pham'].astype(str)
df['ten_san_pham'] = df['ten_san_pham'].astype(str)
danh_gia['ma_san_pham'] = danh_gia['ma_san_pham'].astype(str)

# Táº¡o ba tab: "Theo sáº£n pháº©m" vÃ  "Theo tá»«ng thÆ°Æ¡ng hiá»‡u", "Theo nhiá»u thÆ°Æ¡ng hiá»‡u"
main_tabs = st.tabs(["Theo sáº£n pháº©m", "Theo tá»«ng thÆ°Æ¡ng hiá»‡u", "Theo nhiá»u thÆ°Æ¡ng hiá»‡u"])

# Tab 1: Theo sáº£n pháº©m
with main_tabs[0]:
    filtered_df = df.drop_duplicates(subset='ma_san_pham')

    if not filtered_df.empty:
        product_list = format_product_selection(filtered_df)
        product_list.insert(0, "Chá»n sáº£n pháº©m")  # Default option

        selected_product = st.selectbox("Vui lÃ²ng nháº­p tÃªn sáº£n pháº©m, mÃ£ sáº£n pháº©m hoáº·c chá»n 1 sáº£n pháº©m:", product_list, index=0, key='product_selection')
        
        if selected_product != "Chá»n sáº£n pháº©m":
            selected_code = selected_product.split(" (Code: ")[-1].rstrip(")")
            selected_row = filtered_df[filtered_df['ma_san_pham'] == selected_code].iloc[0]

            st.write("Báº¡n Ä‘Ã£ chá»n:", selected_product)
            st.write("MÃ£ sáº£n pháº©m:", selected_code)

            # Display product information
            display_product_info(selected_row)

            # Call analysis functions
            display_analysis_tabs(selected_code)
    else:
        st.write("KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m.")

# Tab 2: Theo tá»«ng thÆ°Æ¡ng hiá»‡u
with main_tabs[1]:
    brands = get_unique_brands(df)
    brands.insert(0, "Chá»n thÆ°Æ¡ng hiá»‡u")
    
    selected_brand = st.selectbox("Vui lÃ²ng nháº­p hoáº·c chá»n 1 thÆ°Æ¡ng hiá»‡u:", brands)

    if selected_brand != "Chá»n thÆ°Æ¡ng hiá»‡u":
        filtered_brand_df = df[df['thuong_hieu'].str.contains(selected_brand, case=False, na=False)].drop_duplicates(subset='ma_san_pham')
        
        if not filtered_brand_df.empty:
            product_list_brands = filtered_brand_df.apply(lambda x: f"{x['ten_san_pham']} (Code: {x['ma_san_pham']})", axis=1).tolist()

            dis_tabs = st.tabs(['Tá»•ng sáº£n pháº©m', 'DÃ²ng sáº£n pháº©m'])

            with dis_tabs[0]:  # 'Tá»•ng sáº£n pháº©m'
                st.write(f"CÃ³ {filtered_brand_df.shape[0]} sáº£n pháº©m cá»§a thÆ°Æ¡ng hiá»‡u {selected_brand}.")

                rating_counts = (danh_gia.groupby('ma_san_pham')['so_sao'].value_counts().unstack(fill_value=0)).sum(axis=1).reset_index()
                rating_counts.columns = ['ma_san_pham', 'tong_danh_gia']

                rating_summary = filtered_brand_df.merge(rating_counts, on='ma_san_pham', how='left')
                visualize_rating_counts(rating_summary, f'Sá»‘ lÆ°á»£ng Ä‘Ã¡nh giÃ¡ theo sáº£n pháº©m cá»§a thÆ°Æ¡ng hiá»‡u {selected_brand}')

                selected_product_brand = st.selectbox("Chá»n sáº£n pháº©m Ä‘á»ƒ phÃ¢n tÃ­ch:", product_list_brands)
                selected_code_brand = selected_product_brand.split(" (Code: ")[-1].rstrip(")")
                selected_row_2 = filtered_brand_df[filtered_brand_df['ma_san_pham'] == selected_code_brand].iloc[0]

                st.write("Báº¡n Ä‘Ã£ chá»n sáº£n pháº©m:", selected_product_brand)
                st.write("MÃ£ sáº£n pháº©m:", selected_code_brand)

                display_product_info(selected_row_2)

                st.write("Thá»‘ng kÃª sá»‘ lÆ°á»£ng bÃ¬nh luáº­n:")
                sub2_tabs = st.tabs(["ThÃ¡ng", "Giá»", "WordCloud"])
                with sub2_tabs[0]:
                    analyze_comments_by_month(danh_gia, selected_code_brand)
                with sub2_tabs[1]:
                    analyze_comments_by_hour(danh_gia, selected_code_brand)
                with sub2_tabs[2]:
                    plot_product_comments_wordcloud(danh_gia, selected_code_brand)

            # 'DÃ²ng sáº£n pháº©m' logic
            with dis_tabs[1]:
                product_line_counts = filtered_brand_df['dong_san_pham'].value_counts()
                st.write(f"Tá»•ng sá»‘ dÃ²ng sáº£n pháº©m cá»§a thÆ°Æ¡ng hiá»‡u {selected_brand}: {len(product_line_counts)}")

                # Creating tabs for further analysis
                dong_tabs = st.tabs(['Sáº£n pháº©m', 'BÃ¬nh luáº­n', 'ÄÃ¡nh giÃ¡'])

                with dong_tabs[0]:  # 'Sáº£n pháº©m'
                    # Product line visualization
                    product_line_df = pd.DataFrame({
                        'DÃ²ng sáº£n pháº©m': product_line_counts.index,
                        'Sá»‘ lÆ°á»£ng sáº£n pháº©m': product_line_counts.values
                    })
                    fig = px.bar(product_line_df, x='Sá»‘ lÆ°á»£ng sáº£n pháº©m', y='DÃ²ng sáº£n pháº©m',
                                 orientation='h', text='Sá»‘ lÆ°á»£ng sáº£n pháº©m', title=f'PhÃ¢n bá»‘ sá»‘ lÆ°á»£ng sáº£n pháº©m theo dÃ²ng - {selected_brand}')
                    
                    fig.update_traces(textposition='outside')
                    fig.update_layout(yaxis_title="DÃ²ng sáº£n pháº©m", xaxis_title="Sá»‘ lÆ°á»£ng sáº£n pháº©m")
                    st.plotly_chart(fig)

                    # Dropdown to select product line
                    selected_product_line = st.selectbox("Chá»n dÃ²ng sáº£n pháº©m Ä‘á»ƒ xem chi tiáº¿t:", ["Chá»n dÃ²ng sáº£n pháº©m"] + filtered_brand_df['dong_san_pham'].unique().tolist())

                    if selected_product_line != "Chá»n dÃ²ng sáº£n pháº©m":
                        product_line_df = filtered_brand_df[filtered_brand_df['dong_san_pham'] == selected_product_line]
                        st.write(f"CÃ³ {len(product_line_df)} sáº£n pháº©m trong dÃ²ng {selected_product_line}")

                        cols = st.columns(3)  # For displaying product images
                        for idx, row in enumerate(product_line_df.itertuples()):
                            with cols[idx % 3]:
                                st.write(f"**{row.ten_san_pham}**")
                                st.write(f"MÃ£ SP: {row.ma_san_pham}")
                                if pd.notna(row.hinh_anh):
                                    st.image(row.hinh_anh, caption=row.ten_san_pham)
                                st.write("---")

                with dong_tabs[1]:  # 'BÃ¬nh luáº­n'
                    product_comments = pd.merge(filtered_brand_df[['ma_san_pham', 
                                                                  'dong_san_pham']], 
                                                danh_gia[['ma_san_pham', 
                                                           'noi_dung_binh_luan', 
                                                           'phan_loai_danh_gia']], 
                                                on='ma_san_pham', 
                                                how='left')
                    
                    comments_by_line = product_comments.groupby('dong_san_pham')['noi_dung_binh_luan'].count().reset_index(name='Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n')
                    fig1 = px.bar(comments_by_line, 
                                   x='dong_san_pham', 
                                   y='Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n', 
                                   text='Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n',
                                   title=f'PhÃ¢n bá»‘ sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo dÃ²ng sáº£n pháº©m - {selected_brand}')
                    st.plotly_chart(fig1)

                    sentiment_by_line = product_comments.groupby(['dong_san_pham', 'phan_loai_danh_gia']).size().unstack(fill_value=0)
                    st.write("Sá»‘ lÆ°á»£ng bÃ¬nh luáº­n theo sentiment cho tá»«ng dÃ²ng sáº£n pháº©m:")
                    st.dataframe(sentiment_by_line)

                    plot_sentiment_distribution(sentiment_by_line)

                with dong_tabs[2]:  # 'ÄÃ¡nh giÃ¡'
                    rating_counts = pd.merge(filtered_brand_df[['ma_san_pham', 'dong_san_pham']], 
                                                danh_gia[['ma_san_pham', 'so_sao']], 
                                                on='ma_san_pham', 
                                                how='left').groupby(['dong_san_pham', 'so_sao']).size().unstack(fill_value=0)
                    
                    st.write("Sá»‘ lÆ°á»£ng cÃ¡c loáº¡i so_sao theo tá»«ng dÃ²ng sáº£n pháº©m:")
                    st.dataframe(rating_counts)

                    rating_counts_long = rating_counts.reset_index().melt(id_vars='dong_san_pham', var_name='Loáº¡i so_sao', value_name='Sá»‘ lÆ°á»£ng')

                    fig_bar = px.bar(rating_counts_long, 
                                    x='dong_san_pham', 
                                    y='Sá»‘ lÆ°á»£ng', 
                                    color='Loáº¡i so_sao', 
                                    title=f'Sá»‘ lÆ°á»£ng tá»«ng loáº¡i so_sao theo tá»«ng dÃ²ng sáº£n pháº©m - {selected_brand}',
                                    labels={'Sá»‘ lÆ°á»£ng': 'Sá»‘ lÆ°á»£ng', 'dong_san_pham': 'DÃ²ng sáº£n pháº©m'},
                                    barmode='group')
                    fig_bar.update_layout(height=400)
                    st.plotly_chart(fig_bar)

                    if not rating_counts.empty:
                        for column in range(0, len(rating_counts.columns), 2):
                            # Create subplots for every two columns
                            cols = st.columns(2)
                            for col in range(2):
                                idx = column + col
                                if idx < len(rating_counts):
                                    dong_sp = rating_counts.index[idx]
                                    row = rating_counts.loc[dong_sp]
                                    
                                    with cols[col]:
                                        fig = px.pie(values=row.values,
                                                     names=row.index,
                                                     title=f'Tá»· lá»‡ pháº§n trÄƒm cÃ¡c loáº¡i so_sao - {dong_sp}',
                                                     color_discrete_sequence=px.colors.sequential.Plasma)
                                        fig.update_traces(textposition='inside',
                                                          textinfo='percent+value',
                                                          hole=.3)
                                        st.plotly_chart(fig)

                    else:
                        st.write("KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ hiá»ƒn thá»‹.")
        else:
            st.write("KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m cho thÆ°Æ¡ng hiá»‡u nÃ y.")

# Tab 3: Theo nhiá»u thÆ°Æ¡ng hiá»‡u
with main_tabs[2]:
    # Streamlit Configuration
    st.title('Thá»‘ng kÃª ÄÃ¡nh giÃ¡ Sáº£n pháº©m theo ThÆ°Æ¡ng hiá»‡u')

    # Pre-process data once
    df = prepare_data(df)

    # Filter Controls
    col1, col2 = st.columns(2)
    with col1:
        selected_dong_san_pham = st.multiselect('Chá»n DÃ²ng Sáº£n Pháº©m:', sorted(df['dong_san_pham'].unique()))
    with col2:
        if selected_dong_san_pham:
            filtered_brands = sorted(df[df['dong_san_pham'].isin(selected_dong_san_pham)]['thuong_hieu'].unique())
            selected_brands = st.multiselect('Chá»n ThÆ°Æ¡ng hiá»‡u:', filtered_brands)
        else:
            selected_brands = []

    # Review type selection
    review_types = sorted(df['so_sao'].dropna().unique())  # Handle NaN
    selected_review_types = st.multiselect('Chá»n Loáº¡i ÄÃ¡nh giÃ¡:', review_types)

    # Date range selection
    col3, col4 = st.columns(2)
    with col3:
        start_month = st.date_input('ThÃ¡ng báº¯t Ä‘áº§u:', value=df['ngay_binh_luan'].min())
    with col4:
        end_month = st.date_input('ThÃ¡ng káº¿t thÃºc:', value=df['ngay_binh_luan'].max())

    # Hour range selection
    col5, col6 = st.columns(2)
    min_hour, max_hour = df['hour'].min(), df['hour'].max()
    with col5:
        start_hour = st.number_input('Giá» báº¯t Ä‘áº§u:', min_value=min_hour, max_value=max_hour, value=min_hour)
    with col6:
        end_hour = st.number_input('Giá» káº¿t thÃºc:', min_value=start_hour, max_value=max_hour, value=max_hour)

    # Analysis button
    if st.button('Thá»‘ng kÃª'):
        if not (selected_brands and selected_dong_san_pham):
            st.warning('Vui lÃ²ng chá»n Ã­t nháº¥t má»™t thÆ°Æ¡ng hiá»‡u vÃ  má»™t dÃ²ng sáº£n pháº©m.')
            st.stop()

        selected_params = {
            'dong_san_pham': selected_dong_san_pham,
            'brands': selected_brands,
            'review_types': selected_review_types,
            'start_month': start_month,
            'end_month': end_month,
            'start_hour': start_hour,
            'end_hour': end_hour
        }
        
        filtered_df = filter_data(df, selected_params)
        
        if filtered_df.empty:
            st.warning('KhÃ´ng cÃ³ dá»¯ liá»‡u phÃ¹ há»£p vá»›i cÃ¡c tiÃªu chÃ­ Ä‘Ã£ chá»n.')
            st.stop()

        # Create and display charts
        bar_fig, review_counts = create_bar_chart(filtered_df)
        st.pyplot(bar_fig)

        # Create pie chart tabs
        valid_review_types = sorted(set(selected_review_types) & set(review_counts.columns))
        if valid_review_types:
            pie_tabs = st.tabs([f"{review_type} sao" for review_type in valid_review_types])
            for tab, review_type in zip(pie_tabs, valid_review_types):
                with tab:
                    pie_fig = create_pie_chart(review_counts, review_type)
                    st.pyplot(pie_fig)
        else:
            st.warning("KhÃ´ng cÃ³ loáº¡i Ä‘Ã¡nh giÃ¡ nÃ o Ä‘á»ƒ hiá»ƒn thá»‹.")

# ------------END_ Main Streamlit App--------------------